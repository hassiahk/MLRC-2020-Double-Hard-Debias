{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/hassiahk/Double-Hard-Debias/blob/main/notebooks/GloVe_Double_Hard_Debias.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import json\n",
    "import operator\n",
    "from typing import Dict, List, Tuple, Union\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Load the GloVe word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_vec shape: (322636, 300), word2idx length: 322636, vocab length: 322636\n"
     ]
    }
   ],
   "source": [
    "def load_glove_txt(path: str) -> Tuple[np.ndarray, Dict[str, int], List[str]]:\n",
    "    \"\"\"\n",
    "    Loads GloVe embeddings from txt file.\n",
    "    \"\"\"\n",
    "\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as glove_file:\n",
    "        lines = glove_file.readlines()\n",
    "\n",
    "    word_vec = []\n",
    "    vocab = []\n",
    "\n",
    "    for line in lines:\n",
    "        tokens = line.strip().split(\" \")\n",
    "\n",
    "        # `tokens` should be a list of length 301 which consists of the word and the respective 300 dimension word vector\n",
    "        assert len(tokens) == 301\n",
    "\n",
    "        vocab.append(tokens[0])\n",
    "        word_vec.append(tokens[1:])\n",
    "\n",
    "    word2idx = {word: idx for idx, word in enumerate(vocab)}\n",
    "    word_vec = np.array(word_vec).astype(float)\n",
    "    print(f\"word_vec shape: {word_vec.shape}, word2idx length: {len(word2idx)}, vocab length: {len(vocab)}\")\n",
    "\n",
    "    return word_vec, word2idx, vocab\n",
    "\n",
    "word_vec, word2idx, vocab = load_glove_txt('../data/vectors.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Create Male and Female biased word sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Restrict the vocabulary if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 50000/50000 [00:00<00:00, 97505.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 47628\n"
     ]
    }
   ],
   "source": [
    "from double_hard_debias.utils import limit_vocab\n",
    "\n",
    "\n",
    "with open('../data/male_word_file.txt') as f:\n",
    "    gender_specific = [line.strip() for line in f]\n",
    "\n",
    "with open('../data/female_word_file.txt') as f:\n",
    "    for l in f:\n",
    "        gender_specific.append(l.strip())\n",
    "\n",
    "with codecs.open('../data/gender_specific_full.json') as f:\n",
    "    gender_specific.extend(json.load(f))\n",
    "\n",
    "definitional_pairs = [\n",
    "    ['she', 'he'], ['herself', 'himself'], ['her', 'his'], ['daughter', 'son'], ['girl', 'boy'], ['mother', 'father'], \n",
    "    ['woman', 'man'], ['mary', 'john'], ['gal', 'guy'], ['female', 'male']\n",
    "]\n",
    "\n",
    "definitional_words = [word for pair in definitional_pairs for word in pair]\n",
    "\n",
    "# We will be testing the Double-Hard Debias techique to this subset of words.\n",
    "# Excluding the gender specific words from this subset.\n",
    "word_vec_limited, word2idx_limited, vocab_limited = limit_vocab(word_vec, word2idx, vocab, exclude=gender_specific)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute original gender bias of a word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In an ideal case, the gender bias of a word in the vocab_limited should be zero if it is a gender nuetral word\n",
    "# but this does not happen in a real world scenario.\n",
    "\n",
    "# Generally, cosine similarity is used to measure how similar two vectors are.\n",
    "# So, the basic intuition is that if two vectors are similar then the angle and distance between them is 0.\n",
    "# Distance between two vectors = 1 - similarity of two vectors.\n",
    "\n",
    "def cosine_similarity(word_vec1: np.ndarray, word_vec2: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Computes Cosine Similarity between two word embeddings or vectors.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Cosine similarity is nothing but 1 - cosine distance\n",
    "    return 1 - scipy.spatial.distance.cosine(word_vec1, word_vec2)\n",
    "\n",
    "\n",
    "# Gender bias of a word is the difference of the word's similarity to `he` word embedding and \n",
    "# the word's similarity to `she` word embedding.\n",
    "\n",
    "def compute_bias(\n",
    "    word_vec: np.ndarray,\n",
    "    word2idx: Dict[str, int],\n",
    "    vocab: List[str],\n",
    "    he_embed: np.ndarray,\n",
    "    she_embed: np.ndarray,\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Computes bias of each word by taking the difference of the word's similarity to `he` word embedding\n",
    "    and the word's similarity to `she` word embedding.\n",
    "    \"\"\"\n",
    "    \n",
    "    gender_bias = {}\n",
    "\n",
    "    for word in vocab:\n",
    "        vector = word_vec[word2idx[word]]\n",
    "        # There should not be any difference in 'he' similarity and 'she' similarity for a gender neutral word.\n",
    "        gender_bias[word] = cosine_similarity(vector, he_embed) - cosine_similarity(vector, she_embed)\n",
    "\n",
    "    return gender_bias\n",
    "\n",
    "\n",
    "he_embed = word_vec[word2idx['he']]\n",
    "she_embed = word_vec[word2idx['she']]\n",
    "\n",
    "# If this gender bias is > 0 then the word is biased towards male and if < 0 then biased towards female.\n",
    "gender_bias_original = compute_bias(word_vec_limited, word2idx_limited, vocab_limited, he_embed, she_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.012779653811138436"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_bias_original['doctor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As you can see here, no word has zero gender bias.        \n",
    "zero_gender_bias_words = [word for word, bias in gender_bias_original.items() if np.allclose([bias], [0])]\n",
    "zero_gender_bias_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Male and Female biased word sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting gender_bias_original in the ascending order so that all the female biased words will be at the start and\n",
    "# all the male biased words will be at the end.\n",
    "biased_words_sorted = sorted(gender_bias_original.items(), key=operator.itemgetter(1))\n",
    "\n",
    "# Considering 1000 male and 1000 female biased words. \n",
    "# size can be anything, the authors mentioned that they took 500 male and 500 female top biased words.\n",
    "size = 1000\n",
    "female_words = [word for word, bias in biased_words_sorted[:size]]\n",
    "male_words = [word for word, bias in biased_words_sorted[-size:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Decentralize the word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vec_mean = np.mean(word_vec, axis=0)\n",
    "word_vec_decentralized = word_vec - word_vec_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Compute principal components of decentralized word embeddings using PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "def principal_component_analysis(word_vec: np.ndarray) -> PCA:\n",
    "    \"\"\"\n",
    "    Performs PCA on decentralized word embeddings.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Decentalize word embeddings irrespective of whether they are already decentralized because\n",
    "    # mean of decentralized word embeddings is zero.\n",
    "    word_vec_mean = np.mean(word_vec, axis=0)\n",
    "    word_vec_decentralized = word_vec - word_vec_mean\n",
    "\n",
    "    pca = PCA()\n",
    "    pca.fit(word_vec_decentralized)\n",
    "    \n",
    "    return pca\n",
    "\n",
    "main_pca = principal_component_analysis(word_vec_decentralized)\n",
    "# You can access a principal component by main_pca.components_[component_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Find and remove frequency and gender directions from the decentralized word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from double_hard_debias.utils import perform_pca, remove_vector_component\n",
    "\n",
    "\n",
    "def frequency_gender_debias(word_vec, word2idx, word2idx_partial, vocab_partial, component_id):\n",
    "    \"\"\"\n",
    "    Performs frequency and gender debiasing.\n",
    "    \"\"\"\n",
    "    pricipal_component = main_pca.components_[component_id]\n",
    "      \n",
    "    word_vec_frequency = np.zeros((len(vocab_partial), word_vec.shape[1]))\n",
    "\n",
    "    # Debiasing the embeddings by removing frequency component.\n",
    "    for word in vocab_partial:\n",
    "        vector = word_vec[word2idx[word]]\n",
    "        \n",
    "        # pricipal_component is a unit vector since all pricipal components are unit vectors.\n",
    "        # We need to remove the component of vector in the direction of principal_component which is nothing but\n",
    "        # the projection of vector on principal_component.\n",
    "        projection = np.dot(np.dot(np.transpose(pricipal_component), vector), pricipal_component)\n",
    "        word_vec_frequency[word2idx_partial[word]] = vector - projection\n",
    "    \n",
    "    # Debiasing the embeddings by removing gender component.\n",
    "    gender_vector = perform_pca(definitional_pairs, word_vec_frequency, word2idx_partial).components_[0]\n",
    "    word_vec_debiased = np.zeros((len(vocab_partial), word_vec_frequency.shape[1]))\n",
    "    \n",
    "    for word in vocab_partial:\n",
    "        vector = word_vec_frequency[word2idx_partial[word]]\n",
    "        word_vec_debiased[word2idx_partial[word]] = remove_vector_component(vector, gender_vector)\n",
    "        \n",
    "    return word_vec_debiased"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Perform KMeans and evaluate the debiased word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "def cluster_and_evaluate(X, y_true, n_clusters=2, random_state=42) -> Tuple[KMeans, List[int], List[float]]:\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=random_state).fit(X)\n",
    "    y_pred = kmeans.predict(X)\n",
    "    \n",
    "    \n",
    "    result = [1 if target == prediction else 0 for target, prediction in zip(y_true, y_pred)] \n",
    "    accuracy = sum(result) / len(result)\n",
    "    max_accuracy = max(accuracy, 1 - accuracy) # Not sure about this\n",
    "    print(f'Accuracy: {max_accuracy}')\n",
    "    \n",
    "    return kmeans, y_pred, max_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Find the optimal frequency direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component: 0, Pairs used in PCA: 10, Accuracy: 0.817\n",
      "Component: 1, Pairs used in PCA: 10, Accuracy: 0.704\n",
      "Component: 2, Pairs used in PCA: 10, Accuracy: 0.8145\n",
      "Component: 3, Pairs used in PCA: 10, Accuracy: 0.816\n",
      "Component: 4, Pairs used in PCA: 10, Accuracy: 0.802\n",
      "Component: 5, Pairs used in PCA: 10, Accuracy: 0.775\n",
      "Component: 6, Pairs used in PCA: 10, Accuracy: 0.785\n",
      "Component: 7, Pairs used in PCA: 10, Accuracy: 0.8025\n",
      "Component: 8, Pairs used in PCA: 10, Accuracy: 0.807\n",
      "Component: 9, Pairs used in PCA: 10, Accuracy: 0.815\n",
      "Component: 10, Pairs used in PCA: 10, Accuracy: 0.812\n",
      "Component: 11, Pairs used in PCA: 10, Accuracy: 0.818\n",
      "Component: 12, Pairs used in PCA: 10, Accuracy: 0.8180000000000001\n",
      "Component: 13, Pairs used in PCA: 10, Accuracy: 0.8045\n",
      "Component: 14, Pairs used in PCA: 10, Accuracy: 0.8145\n",
      "Component: 15, Pairs used in PCA: 10, Accuracy: 0.811\n",
      "Component: 16, Pairs used in PCA: 10, Accuracy: 0.8145\n",
      "Component: 17, Pairs used in PCA: 10, Accuracy: 0.806\n",
      "Component: 18, Pairs used in PCA: 10, Accuracy: 0.808\n",
      "Component: 19, Pairs used in PCA: 10, Accuracy: 0.8165\n"
     ]
    }
   ],
   "source": [
    "def get_embeddings(words, word_vec, word2idx):\n",
    "    \"\"\"\n",
    "    Get embeddings for the given words.\n",
    "    \"\"\"\n",
    "    embeddings = [word_vec[word2idx[word]] for word in words]\n",
    "    \n",
    "    return embeddings\n",
    "\n",
    "\n",
    "y_true = [1] * size + [0] * size\n",
    "\n",
    "vocab_partial = list(set(male_words + female_words + [word for word in definitional_words if word in word2idx]))\n",
    "word2idx_partial = {word: idx for idx, word in enumerate(vocab_partial)}\n",
    "\n",
    "accuracies = []\n",
    "\n",
    "for i in range(20):\n",
    "    print(f'Component: {i}', end=', ')\n",
    "    \n",
    "    word_vec_debiased = frequency_gender_debias(word_vec_decentralized, word2idx, word2idx_partial, vocab_partial, i)\n",
    "    kmeans, y_pred, max_accuracy = cluster_and_evaluate(\n",
    "        get_embeddings(male_words + female_words, word_vec_debiased, word2idx_partial), y_true, random_state=1 \n",
    "    )\n",
    "    accuracies.append(max_accuracy)\n",
    "\n",
    "optimal_frequency_direction = accuracies.index(min(accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x201.6 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "directions = np.arange(1, 21)\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(6,2.8))\n",
    "\n",
    "color = 'red'\n",
    "ax1.set_xlabel('Project out the D-th directions', fontsize=17)\n",
    "ax1.set_ylabel('Accuracy', fontsize=17)\n",
    "ax1.scatter(directions, accuracies, color=color, label='GloVe', marker='x', s=60)\n",
    "plt.xticks(list(range(0, 21, 2)), fontsize=15)\n",
    "ax1.tick_params(axis='y', labelsize=14)\n",
    "ax1.set_ylim(0.65, 0.84)\n",
    "ax1.legend(loc='lower right', frameon=True, fontsize='large')\n",
    "ax1.grid(axis='y')\n",
    "\n",
    "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Double-Hard Debias (Debiasing Frequency and Gender components) the original word embeddings in the optimal frequency direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pairs used in PCA: 10, "
     ]
    }
   ],
   "source": [
    "from double_hard_debias.utils import perform_pca, remove_vector_component\n",
    "\n",
    "\n",
    "pricipal_component = main_pca.components_[optimal_frequency_direction]\n",
    "\n",
    "word_vec_frequency = np.zeros((len(vocab), word_vec.shape[1]))\n",
    "\n",
    "for word in vocab:\n",
    "    vector = word_vec[word2idx[word]]\n",
    "    \n",
    "    projection = np.dot(np.dot(np.transpose(pricipal_component), vector), pricipal_component)\n",
    "    word_vec_frequency[word2idx[word]] = vector - projection - word_vec_mean\n",
    "\n",
    "gender_vector = perform_pca(definitional_pairs, word_vec_frequency, word2idx).components_[0]\n",
    "word_vec_debiased = np.zeros((len(vocab), word_vec_frequency.shape[1]))\n",
    "\n",
    "for word in vocab:\n",
    "    vector = word_vec_frequency[word2idx[word]]\n",
    "    word_vec_debiased[word2idx[word]] = remove_vector_component(vector, gender_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 9: Saving word embeddings in a text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_embeddings_to_txt(word_vector: Union[np.array, List[List[float]]], vocabulary: List[str], file_path: str):\n",
    "    \"\"\"\n",
    "    Saves word embeddings to a test file.\n",
    "    \"\"\"\n",
    "    with open(file_path, mode='wt', encoding='utf-8') as f:\n",
    "        for i, word_vec in enumerate(word_vector):\n",
    "            f.write(vocabulary[i] + ' ')\n",
    "            f.write(' '.join(str(vec) for vec in word_vec))\n",
    "            f.write('\\n')\n",
    "            \n",
    "save_embeddings_to_txt(word_vec_debiased, vocab, '../data/glove_dhd.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rc2020",
   "language": "python",
   "name": "rc2020"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
