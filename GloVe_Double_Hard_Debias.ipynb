{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/hassiahk/Double-Hard-Debias/blob/main/GloVe_Double_Hard_Debias.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import json\n",
    "import operator\n",
    "from typing import Tuple, Dict, List\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Load the GloVe word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_vec shape: (322636, 300), word2idx length: 322636, vocab length: 322636\n"
     ]
    }
   ],
   "source": [
    "def load_glove_txt(path: str) -> Tuple[np.ndarray, Dict[str, int], List[str]]:\n",
    "    \"\"\"\n",
    "    Loads GloVe embeddings from txt file.\n",
    "    \"\"\"\n",
    "\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as glove_file:\n",
    "        lines = glove_file.readlines()\n",
    "\n",
    "    word_vec = []\n",
    "    vocab = []\n",
    "\n",
    "    for line in lines:\n",
    "        tokens = line.strip().split(\" \")\n",
    "\n",
    "        # `tokens` should be a list of length 301 which consists of the word and the respective 300 dimension word vector\n",
    "        assert len(tokens) == 301\n",
    "\n",
    "        vocab.append(tokens[0])\n",
    "        word_vec.append(tokens[1:])\n",
    "\n",
    "    word2idx = {word: idx for idx, word in enumerate(vocab)}\n",
    "    word_vec = np.array(word_vec).astype(float)\n",
    "    print(f\"word_vec shape: {word_vec.shape}, word2idx length: {len(word2idx)}, vocab length: {len(vocab)}\")\n",
    "\n",
    "    return word_vec, word2idx, vocab\n",
    "\n",
    "word_vec, word2idx, vocab = load_glove_txt('./data/vectors.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Create Male and Female biased word sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Restrict the vocabulary if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 50000/50000 [00:00<00:00, 76214.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 47628\n"
     ]
    }
   ],
   "source": [
    "from utils import limit_vocab\n",
    "\n",
    "\n",
    "with open('./data/male_word_file.txt') as f:\n",
    "    gender_specific = [line.strip() for line in f]\n",
    "\n",
    "with open('./data/female_word_file.txt') as f:\n",
    "    for l in f:\n",
    "        gender_specific.append(l.strip())\n",
    "\n",
    "with codecs.open('./data/gender_specific_full.json') as f:\n",
    "    gender_specific.extend(json.load(f))\n",
    "\n",
    "definitional_pairs = [\n",
    "    ['she', 'he'], ['herself', 'himself'], ['her', 'his'], ['daughter', 'son'], ['girl', 'boy'], ['mother', 'father'], \n",
    "    ['woman', 'man'], ['mary', 'john'], ['gal', 'guy'], ['female', 'male']\n",
    "]\n",
    "\n",
    "definitional_words = [word for pair in definitional_pairs for word in pair]\n",
    "\n",
    "# We will be testing the Double-Hard Debias techique to this subset of words.\n",
    "# Excluding the gender specific words from this subset.\n",
    "word_vec_limited, word2idx_limited, vocab_limited = limit_vocab(word_vec, word2idx, vocab, exclude=gender_specific)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute original gender bias of a word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In an ideal case, the gender bias of a word in the vocab_limited should be zero if it is a gender nuetral word\n",
    "# but this does not happen in a real world scenario.\n",
    "\n",
    "# Generally, cosine similarity is used to measure how similar two vectors are.\n",
    "# So, the basic intuition is that if two vectors are similar then the angle and distance between them is 0.\n",
    "# Distance between two vectors = 1 - similarity of two vectors.\n",
    "\n",
    "def cosine_similarity(word_vec1: np.ndarray, word_vec2: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Computes Cosine Similarity between two word embeddings or vectors.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Cosine similarity is nothing but 1 - cosine distance\n",
    "    return 1 - scipy.spatial.distance.cosine(word_vec1, word_vec2)\n",
    "\n",
    "\n",
    "# Gender bias of a word is the difference of the word's similarity to `he` word embedding and \n",
    "# the word's similarity to `she` word embedding.\n",
    "\n",
    "def compute_bias(\n",
    "    word_vec: np.ndarray,\n",
    "    word2idx: Dict[str, int],\n",
    "    vocab: List[str],\n",
    "    he_embed: np.ndarray,\n",
    "    she_embed: np.ndarray,\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Computes bias of each word by taking the difference of the word's similarity to `he` word embedding\n",
    "    and the word's similarity to `she` word embedding.\n",
    "    \"\"\"\n",
    "    \n",
    "    gender_bias = {}\n",
    "\n",
    "    for word in vocab:\n",
    "        vector = word_vec[word2idx[word]]\n",
    "        # There should not be any difference in 'he' similarity and 'she' similarity for a gender neutral word.\n",
    "        gender_bias[word] = cosine_similarity(vector, he_embed) - cosine_similarity(vector, she_embed)\n",
    "\n",
    "    return gender_bias\n",
    "\n",
    "\n",
    "he_embed = word_vec[word2idx['he']]\n",
    "she_embed = word_vec[word2idx['she']]\n",
    "\n",
    "# If this gender bias is > 0 then the word is biased towards male and if < 0 then biased towards female.\n",
    "gender_bias_original = compute_bias(word_vec_limited, word2idx_limited, vocab_limited, he_embed, she_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.012779653811138436"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_bias_original['doctor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As you can see here, no word has zero gender bias.        \n",
    "zero_gender_bias_words = [word for word, bias in gender_bias_original.items() if np.allclose([bias], [0])]\n",
    "zero_gender_bias_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Male and Female biased word sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting gender_bias_original in the ascending order so that all the female biased words will be at the start and\n",
    "# all the male biased words will be at the end.\n",
    "biased_words_sorted = sorted(gender_bias_original.items(), key=operator.itemgetter(1))\n",
    "\n",
    "# Considering 1000 male and 1000 female biased words. \n",
    "# size can be anything, the authors mentioned that they took 500 male and 500 female top biased words.\n",
    "size = 1000\n",
    "female_words = [word for word, bias in biased_words_sorted[:size]]\n",
    "male_words = [word for word, bias in biased_words_sorted[-size:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Decentralize the word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vec_mean = np.mean(word_vec, axis=0)\n",
    "word_vec_decentralized = word_vec - word_vec_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Compute principal components of decentralized word embeddings using PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "def principal_component_analysis(word_vec: np.ndarray) -> PCA:\n",
    "    \"\"\"\n",
    "    Performs PCA on decentralized word embeddings.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Decentalize word embeddings irrespective of whether they are already decentralized because\n",
    "    # mean of decentralized word embeddings is zero.\n",
    "    word_vec_mean = np.mean(word_vec, axis=0)\n",
    "    word_vec_decentralized = word_vec - word_vec_mean\n",
    "\n",
    "    pca = PCA()\n",
    "    pca.fit(word_vec_decentralized)\n",
    "    \n",
    "    return pca\n",
    "\n",
    "main_pca = principal_component_analysis(word_vec_decentralized)\n",
    "# You can access a principal component by main_pca.components_[component_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Find and remove frequency and gender directions from the decentralized word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import perform_pca, remove_vector_component\n",
    "\n",
    "\n",
    "def frequency_gender_debias(word_vec, word2idx, word2idx_partial, vocab_partial, component_id):\n",
    "    pricipal_component = main_pca.components_[component_id]\n",
    "      \n",
    "    word_vec_frequency = np.zeros((len(vocab_partial), word_vec.shape[1]))\n",
    "\n",
    "    # Debiasing the embeddings by removing frequency component.\n",
    "    for word in vocab_partial:\n",
    "        vector = word_vec[word2idx[word]]\n",
    "        \n",
    "        # pricipal_component is a unit vector since all pricipal components are unit vectors.\n",
    "        # We need to remove the component of vector in the direction of principal_component which is nothing but\n",
    "        # the projection of vector on principal_component.\n",
    "        projection = np.dot(np.dot(np.transpose(pricipal_component), vector), pricipal_component)\n",
    "        word_vec_frequency[word2idx_partial[word]] = vector - projection\n",
    "    \n",
    "    # Debiasing the embeddings by removing gender component.\n",
    "    gender_vector = perform_pca(definitional_pairs, word_vec_frequency, word2idx_partial).components_[0]\n",
    "    word_vec_debiased = np.zeros((len(vocab_partial), word_vec_frequency.shape[1]))\n",
    "    \n",
    "    for word in vocab_partial:\n",
    "        vector = word_vec_frequency[word2idx_partial[word]]\n",
    "        word_vec_debiased[word2idx_partial[word]] = remove_vector_component(vector, gender_vector)\n",
    "        \n",
    "    return word_vec_debiased"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Perform KMeans and evaluate the debiased word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "def cluster_and_evaluate(X, y_true, n_clusters=2, random_state=42) -> Tuple[KMeans, List[int], List[float]]:\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=random_state).fit(X)\n",
    "    y_pred = kmeans.predict(X)\n",
    "    \n",
    "    \n",
    "    result = [1 if target == prediction else 0 for target, prediction in zip(y_true, y_pred)] \n",
    "    accuracy = sum(result) / len(result)\n",
    "    precision = max(accuracy, 1 - accuracy) # Not sure about this\n",
    "    print(f'Precision: {precision}')\n",
    "    \n",
    "    return kmeans, y_pred, precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Find the optimal frequency direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component: 0\n",
      "Pairs used in PCA: 10\n",
      "Precision: 0.817\n",
      "Component: 1\n",
      "Pairs used in PCA: 10\n",
      "Precision: 0.704\n",
      "Component: 2\n",
      "Pairs used in PCA: 10\n",
      "Precision: 0.8145\n",
      "Component: 3\n",
      "Pairs used in PCA: 10\n",
      "Precision: 0.816\n",
      "Component: 4\n",
      "Pairs used in PCA: 10\n",
      "Precision: 0.802\n",
      "Component: 5\n",
      "Pairs used in PCA: 10\n",
      "Precision: 0.775\n",
      "Component: 6\n",
      "Pairs used in PCA: 10\n",
      "Precision: 0.785\n",
      "Component: 7\n",
      "Pairs used in PCA: 10\n",
      "Precision: 0.8025\n",
      "Component: 8\n",
      "Pairs used in PCA: 10\n",
      "Precision: 0.807\n",
      "Component: 9\n",
      "Pairs used in PCA: 10\n",
      "Precision: 0.815\n",
      "Component: 10\n",
      "Pairs used in PCA: 10\n",
      "Precision: 0.812\n",
      "Component: 11\n",
      "Pairs used in PCA: 10\n",
      "Precision: 0.818\n",
      "Component: 12\n",
      "Pairs used in PCA: 10\n",
      "Precision: 0.8180000000000001\n",
      "Component: 13\n",
      "Pairs used in PCA: 10\n",
      "Precision: 0.8045\n",
      "Component: 14\n",
      "Pairs used in PCA: 10\n",
      "Precision: 0.8145\n",
      "Component: 15\n",
      "Pairs used in PCA: 10\n",
      "Precision: 0.811\n",
      "Component: 16\n",
      "Pairs used in PCA: 10\n",
      "Precision: 0.8145\n",
      "Component: 17\n",
      "Pairs used in PCA: 10\n",
      "Precision: 0.806\n",
      "Component: 18\n",
      "Pairs used in PCA: 10\n",
      "Precision: 0.808\n",
      "Component: 19\n",
      "Pairs used in PCA: 10\n",
      "Precision: 0.8165\n"
     ]
    }
   ],
   "source": [
    "def get_embeddings(words, word_vec, word2idx):\n",
    "    \"\"\"\n",
    "    Get embeddings for the given words.\n",
    "    \"\"\"\n",
    "    embeddings = [word_vec[word2idx[word]] for word in words]\n",
    "    \n",
    "    return embeddings\n",
    "\n",
    "\n",
    "y_true = [1] * size + [0] * size\n",
    "\n",
    "vocab_partial = list(set(male_words + female_words + [word for word in definitional_words if word in word2idx]))\n",
    "word2idx_partial = {word: idx for idx, word in enumerate(vocab_partial)}\n",
    "\n",
    "precisions = []\n",
    "\n",
    "for i in range(20):\n",
    "    print(f'Component: {i}')\n",
    "    \n",
    "    word_vec_debiased = frequency_gender_debias(word_vec_decentralized, word2idx, word2idx_partial, vocab_partial, i)\n",
    "    kmeans, y_pred, precision = cluster_and_evaluate(\n",
    "        get_embeddings(male_words + female_words, word_vec_debiased, word2idx_partial), y_true, random_state=1 \n",
    "    )\n",
    "    precisions.append(precision)\n",
    "\n",
    "optimal_frequency_direction = precisions.index(min(precisions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x201.6 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "directions = np.arange(1, 21)\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(6,2.8))\n",
    "\n",
    "color = 'red'\n",
    "ax1.set_xlabel('Project out the D-th directions', fontsize=17)\n",
    "ax1.set_ylabel('Precision', fontsize=17)\n",
    "ax1.scatter(directions, precisions, color=color, label='GloVe', marker = 'x', s=60)\n",
    "plt.xticks(list(range(0, 21, 2)), fontsize=15)\n",
    "ax1.tick_params(axis='y', labelsize=14)\n",
    "ax1.set_ylim(0.65, 0.84)\n",
    "ax1.legend(loc='lower right', frameon=True, fontsize='large')\n",
    "ax1.grid(axis='y')\n",
    "\n",
    "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Double-Hard Debias (Debiasing Frequency and Gender components) the original word embeddings in the optimal frequency direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import perform_pca, remove_vector_component\n",
    "\n",
    "pricipal_component = main_pca.components_[optimal_frequency_direction]\n",
    "\n",
    "word_vec_frequency = np.zeros((len(vocab), word_vec.shape[1]))\n",
    "\n",
    "for word in vocab:\n",
    "    vector = word_vec[word2idx[word]]\n",
    "    \n",
    "    projection = np.dot(np.dot(np.transpose(pricipal_component), vector), pricipal_component)\n",
    "    word_vec_frequency[word2idx[word]] = vector - projection - word_vec_mean\n",
    "\n",
    "gender_vector = perform_pca(definitional_pairs, word_vec_frequency, word2idx).components_[0]\n",
    "word_vec_debiased = np.zeros((len(vocab), word_vec_frequency.shape[1]))\n",
    "\n",
    "for word in vocab:\n",
    "    vector = word_vec_frequency[word2idx[word]]\n",
    "    word_vec_debiased[word2idx[word]] = remove_vector_component(vector, gender_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
